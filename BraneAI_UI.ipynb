{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqhMlM0EnxcOorFai2aXHR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/3d3n-ops/BraneAI/blob/main/BraneAI_UI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UI for BraneAI"
      ],
      "metadata": {
        "id": "kigM_-Puqfav"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwr1f2AcqXkI",
        "outputId": "1fa1efe7-025d-4206-b0ad-7e6926d40b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.40.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.40.1-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, python-dotenv, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.1 python-dotenv-1.0.1 streamlit-1.40.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "import os"
      ],
      "metadata": {
        "id": "NeOKZIb8qoA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "ngrok.set_auth_token(ngrok_token)"
      ],
      "metadata": {
        "id": "W7bFIkguqrcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5caf1c7e-6982-486c-84c8-74bf6c7a3685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_streamlit():\n",
        "\tos.system(\"streamlit run /content/app.py --server.port 8501\")"
      ],
      "metadata": {
        "id": "cu6JY7NOqwvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import cv2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "import google.generativeai as genai\n",
        "import PIL.Image\n",
        "import os\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
        "genai.configure(api_key = api_key)\n",
        "\n",
        "output_dir = 'saliency_maps'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# Function to generate explanations\n",
        "\n",
        "def generate_explanation(img_path, model_prediction, confidence):\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert neurologist. You are tasked with explaining a saliency map of a brain tumor MRI scan.\n",
        "    The saliency map was generated by a deep learning model that was trained to classify brain tumors as either glioma, meningioma, pituitary, or no tumor.\n",
        "\n",
        "    The deep learning model predicted the image as class '{model_prediction}' with a confidence of {confidence * 100:.2f}%.\n",
        "\n",
        "    In your response (indented):\n",
        "        - Explain what regions of the brain the model is focusing on, based on the saliency map.\n",
        "        - Refer to the highlighted regions of the map in light cyan to be exact. These are the high focus areas.\n",
        "        - Explain possible reasons why the model made the prediction it did.\n",
        "    \"\"\"\n",
        "\n",
        "    # Example placeholder for generating a response using Gemini\n",
        "    model = genai.GenerativeModel(model_name='gemini-1.5-flash')\n",
        "    response = model.generate_content(prompt)\n",
        "    st.markdown(response)\n",
        "    return response\n",
        "\n",
        "# Extract the explanation text from the Gemini response\n",
        "def extract_gemini_response(response):\n",
        "    try:\n",
        "        # Navigate to the text part of the response\n",
        "        explanation = response.result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "        return explanation\n",
        "    except (KeyError, IndexError, AttributeError) as e:\n",
        "        return f\"Error extracting explanation: {e}\"\n",
        "\n",
        "\n",
        "# Function to generate a saliency map\n",
        "def generate_saliency_map(model, img_array, class_index, img_size):\n",
        "    with tf.GradientTape() as tape:\n",
        "        img_tensor = tf.convert_to_tensor(img_array)\n",
        "        tape.watch(img_tensor)\n",
        "        predictions = model(img_tensor)\n",
        "        target_class = predictions[:, class_index]\n",
        "\n",
        "    gradients = tape.gradient(target_class, img_tensor)\n",
        "    gradients = tf.math.abs(gradients)\n",
        "    gradients = tf.reduce_max(gradients, axis=-1).numpy().squeeze()\n",
        "    gradients = gradients.squeeze()\n",
        "\n",
        "    # Resize gradients to match original image size\n",
        "    gradients = cv2.resize(gradients, img_size)\n",
        "\n",
        "    # Create circular mask for the brain area\n",
        "    center = (gradients.shape[0] // 2, gradients.shape[1] // 2)\n",
        "    radius = min(center[0], center[1]) - 10\n",
        "    y, x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]\n",
        "    mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2\n",
        "\n",
        "    # Apply mask to gradients\n",
        "    gradients = gradients * mask\n",
        "\n",
        "    # Normalize brain area\n",
        "    brain_gradients = gradients[mask]\n",
        "    if brain_gradients.max() > brain_gradients.min():\n",
        "        brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())\n",
        "    gradients[mask] = brain_gradients\n",
        "\n",
        "    #Apply a higher threshold\n",
        "    threshold = np.percentile(gradients[mask], 80)\n",
        "    gradients[gradients < threshold] = 0\n",
        "\n",
        "    # Enhance gradients\n",
        "    gradients = cv2.GaussianBlur(gradients, (11, 11), 0)\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)\n",
        "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize heatmap and superimpose it on the original image\n",
        "    original_img = img_array.squeeze()\n",
        "    heatmap = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))\n",
        "    superimposed_img = (0.7 * heatmap + 0.3 * original_img).astype(np.uint8)\n",
        "\n",
        "    ig_path = os.path.join(output_dir, f\"ig_{class_index}.jpg\")\n",
        "\n",
        "    # Save the saliency map\n",
        "    saliency_map_path = os.path.join(output_dir, f'saliency_map_{class_index}.jpg')\n",
        "    cv2.imwrite(saliency_map_path, (cv2.cvtColorsuperimposed_img, cv2.COLOR_RGB2BGR))\n",
        "    return superimposed_img\n",
        "\n",
        "# Function to load the Xception model\n",
        "def load_xception_model(model_path):\n",
        "    img_shape = (299, 299, 3)\n",
        "    base_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_shape=img_shape, pooling='max')\n",
        "\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        Flatten(),\n",
        "        Dropout(rate=0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(rate=0.25),\n",
        "        Dense(4, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adamax(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy', Precision(), Recall()]\n",
        "    )\n",
        "\n",
        "    model.load_weights(model_path)\n",
        "    return model\n",
        "\n",
        "#Streamlit UI\n",
        "st.title(\"BraneAI:Tumor Classification Web App\")\n",
        "st.write(\"Upload an image of a brain MRI scan to classify.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image…\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    selected_model = st.radio(\"Select Model\", (\"Transfer Learning - Xception\", \"Custom CNN\"))\n",
        "\n",
        "    if selected_model == \"Transfer Learning - Xception\":\n",
        "        img = PIL.Image.open(uploaded_file)\n",
        "        img_array = np.array(img)\n",
        "        model = load_xception_model('/content/xception_model.weights.h5')\n",
        "        img_size = (299, 299)\n",
        "    else:\n",
        "        img = PIL.Image.open(uploaded_file)\n",
        "        img_array = np.array(img)\n",
        "        model = load_model('/content/cnn_model.h5')\n",
        "        img_size = (299, 299)\n",
        "\n",
        "    labels = ['Glioma', 'Meningioma', 'No tumor', 'Pituitary']\n",
        "    img = image.load_img(uploaded_file, target_size=img_size)\n",
        "    img_array = np.expand_dims(image.img_to_array(img), axis=0) / 255.0\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    class_index = np.argmax(predictions[0])\n",
        "    result = labels[class_index]\n",
        "\n",
        "    img_path = os.path.join(output_dir, f\"{class_index}_saliency_map.jpg\")\n",
        "\n",
        "    st.write(f\"Predicted Class: {result}\")\n",
        "    st.write(\"Predictions:\")\n",
        "    for label, prob in zip(labels, predictions[0]):\n",
        "        st.write(f\"{label}: {prob:.4f}\")\n",
        "\n",
        "    saliency_map = generate_saliency_map(model, img_array, class_index, img_size)\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.image(uploaded_file, caption='Uploaded Image', use_container_width=True)\n",
        "    with col2:\n",
        "        st.image(saliency_map, caption='Saliency Map', use_container_width=True)\n",
        "\n",
        "    saliency_map_path = os.path.join(output_dir, f\"saliency_maps/{uploaded_file.name}\")\n",
        "    explanation = generate_explanation(saliency_map_path, result, predictions[0][class_index])\n",
        "\n",
        "    st.write(\"## Explanation\")\n",
        "    st.write(explanation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TNk4WHqqzT-",
        "outputId": "6b1d0912-7655-4ab1-8977-8991abc475cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thread = Thread(target=run_streamlit)\n",
        "thread.start()"
      ],
      "metadata": {
        "id": "p2mPlEyYrBCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(addr='8501', proto='http', bind_tls=True)\n",
        "print(\"Public URL:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm8WGGK_rDtu",
        "outputId": "966c53a5-3d0b-49d4-e9a8-4bfcc440f616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://89a6-34-74-142-251.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tunnels = ngrok.get_tunnels()\n",
        "for tunnel in tunnels:\n",
        "\tprint(f\"Closing tunnel: {tunnel.public_url} -> {tunnel.config['addr']}\")\n",
        "\tngrok.disconnect(tunnel.public_url)"
      ],
      "metadata": {
        "id": "K3Ii2IYorMJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38844af9-69ce-4149-d5fd-77bcbb06d828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-11-25T01:55:10+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-7904bc31-3100-4b26-a307-bb5bce4f4e7a acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing tunnel: https://bf50-34-74-142-251.ngrok-free.app -> http://localhost:8501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "\n",
        "GOOGLE_API_KEY = "YOUR_GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "jASf49g5sXas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51366484-513d-420d-acdd-4fc38f107d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.environ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5glFt1sq_78w",
        "outputId": "93e649c6-c2eb-48e6-b8e6-0fdd880b7e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "environ({'SHELL': '/bin/bash', 'NV_LIBCUBLAS_VERSION': '12.2.5.6-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'COLAB_JUPYTER_TRANSPORT': 'ipc', 'NV_NVML_DEV_VERSION': '12.2.140-1', 'NV_CUDNN_PACKAGE_NAME': 'libcudnn8', 'CGROUP_MEMORY_EVENTS': '/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events', 'NV_LIBNCCL_DEV_PACKAGE': 'libnccl-dev=2.19.3-1+cuda12.2', 'NV_LIBNCCL_DEV_PACKAGE_VERSION': '2.19.3-1', 'VM_GCE_METADATA_HOST': '169.254.169.253', 'HOSTNAME': 'e250c218d1cd', 'LANGUAGE': 'en_US', 'TBE_RUNTIME_ADDR': '172.28.0.1:8011', 'COLAB_TPU_1VM': '', 'GCE_METADATA_TIMEOUT': '3', 'NVIDIA_REQUIRE_CUDA': 'cuda>=12.2 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=525,driver<526 brand=unknown,driver>=525,driver<526 brand=nvidia,driver>=525,driver<526 brand=nvidiartx,driver>=525,driver<526 brand=geforce,driver>=525,driver<526 brand=geforcertx,driver>=525,driver<526 brand=quadro,driver>=525,driver<526 brand=quadrortx,driver>=525,driver<526 brand=titan,driver>=525,driver<526 brand=titanrtx,driver>=525,driver<526', 'NV_LIBCUBLAS_DEV_PACKAGE': 'libcublas-dev-12-2=12.2.5.6-1', 'NV_NVTX_VERSION': '12.2.140-1', 'COLAB_JUPYTER_IP': '172.28.0.12', 'NV_CUDA_CUDART_DEV_VERSION': '12.2.140-1', 'NV_LIBCUSPARSE_VERSION': '12.1.2.141-1', 'COLAB_LANGUAGE_SERVER_PROXY_ROOT_URL': 'http://172.28.0.1:8013/', 'NV_LIBNPP_VERSION': '12.2.1.4-1', 'NCCL_VERSION': '2.19.3-1', 'KMP_LISTEN_PORT': '6000', 'TF_FORCE_GPU_ALLOW_GROWTH': 'true', 'ENV': '/root/.bashrc', 'PWD': '/', 'TBE_EPHEM_CREDS_ADDR': '172.28.0.1:8009', 'COLAB_LANGUAGE_SERVER_PROXY_REQUEST_TIMEOUT': '30s', 'TBE_CREDS_ADDR': '172.28.0.1:8008', 'NV_CUDNN_PACKAGE': 'libcudnn8=8.9.6.50-1+cuda12.2', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'COLAB_JUPYTER_TOKEN': '', 'LAST_FORCED_REBUILD': '20241028', 'NV_NVPROF_DEV_PACKAGE': 'cuda-nvprof-12-2=12.2.142-1', 'NV_LIBNPP_PACKAGE': 'libnpp-12-2=12.2.1.4-1', 'NV_LIBNCCL_DEV_PACKAGE_NAME': 'libnccl-dev', 'TCLLIBPATH': '/usr/share/tcltk/tcllib1.20', 'NV_LIBCUBLAS_DEV_VERSION': '12.2.5.6-1', 'NVIDIA_PRODUCT_NAME': 'CUDA', 'COLAB_KERNEL_MANAGER_PROXY_HOST': '172.28.0.12', 'NV_LIBCUBLAS_DEV_PACKAGE_NAME': 'libcublas-dev-12-2', 'NV_CUDA_CUDART_VERSION': '12.2.140-1', 'COLAB_WARMUP_DEFAULTS': '1', 'HOME': '/root', 'LANG': 'en_US.UTF-8', 'COLUMNS': '100', 'CUDA_VERSION': '12.2.2', 'CLOUDSDK_CONFIG': '/content/.config', 'NV_LIBCUBLAS_PACKAGE': 'libcublas-12-2=12.2.5.6-1', 'NV_CUDA_NSIGHT_COMPUTE_DEV_PACKAGE': 'cuda-nsight-compute-12-2=12.2.2-1', 'COLAB_RELEASE_TAG': 'release-colab_20241115-060121_RC00', 'KMP_TARGET_PORT': '9000', 'KMP_EXTRA_ARGS': '--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https://colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/m-s-g45h2fo6aups --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true', 'NV_LIBNPP_DEV_PACKAGE': 'libnpp-dev-12-2=12.2.1.4-1', 'COLAB_LANGUAGE_SERVER_PROXY_LSP_DIRS': '/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages', 'NV_LIBCUBLAS_PACKAGE_NAME': 'libcublas-12-2', 'COLAB_KERNEL_MANAGER_PROXY_PORT': '6000', 'CLOUDSDK_PYTHON': 'python3', 'NV_LIBNPP_DEV_VERSION': '12.2.1.4-1', 'NO_GCE_CHECK': 'False', 'PYTHONPATH': '/env/python', 'NV_LIBCUSPARSE_DEV_VERSION': '12.1.2.141-1', 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs', 'NV_CUDNN_VERSION': '8.9.6.50', 'SHLVL': '0', 'NV_CUDA_LIB_VERSION': '12.2.2-1', 'COLAB_LANGUAGE_SERVER_PROXY': '/usr/colab/bin/language_service', 'NVARCH': 'x86_64', 'NV_CUDNN_PACKAGE_DEV': 'libcudnn8-dev=8.9.6.50-1+cuda12.2', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-12-2', 'NV_LIBNCCL_PACKAGE': 'libnccl2=2.19.3-1+cuda12.2', 'LD_LIBRARY_PATH': '/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'COLAB_GPU': '', 'NV_CUDA_NSIGHT_COMPUTE_VERSION': '12.2.2-1', 'GCS_READ_CACHE_BLOCK_SIZE_MB': '16', 'NV_NVPROF_VERSION': '12.2.142-1', 'LC_ALL': 'en_US.UTF-8', 'COLAB_FILE_HANDLER_ADDR': 'localhost:3453', 'PATH': '/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin', 'NV_LIBNCCL_PACKAGE_NAME': 'libnccl2', 'COLAB_DEBUG_ADAPTER_MUX_PATH': '/usr/local/bin/dap_multiplexer', 'NV_LIBNCCL_PACKAGE_VERSION': '2.19.3-1', 'PYTHONWARNINGS': 'ignore:::pip._internal.cli.base_command', 'DEBIAN_FRONTEND': 'noninteractive', 'COLAB_BACKEND_VERSION': 'next', 'OLDPWD': '/', 'JPY_PARENT_PID': '86', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline', 'ENABLE_DIRECTORYPREFETCHER': '1', 'USE_AUTH_EPHEM': '1', 'PYDEVD_USE_FRAME_EVAL': 'NO'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oz4Q1Tb2vDOu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
